name: Peer Score CI

on:
  schedule:
    # Run daily at 11 AM UTC
    - cron: '0 11 * * *'
  workflow_dispatch:
    inputs:
      duration:
        description: 'Test duration (e.g., 10m, 1h)'
        default: '10m'
        required: false
      chain:
        description: 'Ethereum chain'
        default: 'mainnet'
        required: false

jobs:
  peer-score-test:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'
          
      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc
          
      - name: Build Latest Hermes
        run: |
          # Clone and build latest hermes from source
          git clone https://github.com/ethpandaops/hermes.git hermes-repo
          cd hermes-repo
          LATEST_COMMIT=$(git rev-parse --short HEAD)
          go build -o ../hermes ./cmd/hermes
          cd ..
          chmod +x ./hermes
          echo "Built Hermes from commit: $LATEST_COMMIT"
          
      - name: Build Peer Score Tool
        run: |
          go mod tidy
          go build -o peer-score-tool
          
      - name: Run Peer Score Test
        env:
          DURATION: ${{ github.event.inputs.duration || '10m' }}
          CHAIN: ${{ github.event.inputs.chain || 'mainnet' }}
        run: |
          ./peer-score-tool \
            --prysm-host="${{ secrets.PRYSM_HOST }}" \
            --prysm-http-port=443 \
            --prysm-grpc-port=443 \
            --duration="$DURATION" \
            --output=peer-score-report.json
            
      - name: Parse Results
        id: results
        run: |
          if [ -f peer-score-report.json ]; then
            score=$(jq -r '.overall_score' peer-score-report.json)
            connections=$(jq -r '.total_connections' peer-score-report.json)
            handshakes=$(jq -r '.successful_handshakes' peer-score-report.json)
            clients=$(jq -r '.unique_clients' peer-score-report.json)
            goodbyes=$(jq -r '.goodbye_messages' peer-score-report.json)
            summary=$(jq -r '.summary' peer-score-report.json)
            
            echo "score=$score" >> $GITHUB_OUTPUT
            echo "connections=$connections" >> $GITHUB_OUTPUT
            echo "handshakes=$handshakes" >> $GITHUB_OUTPUT
            echo "clients=$clients" >> $GITHUB_OUTPUT
            echo "goodbyes=$goodbyes" >> $GITHUB_OUTPUT
            echo "summary=$summary" >> $GITHUB_OUTPUT
          else
            echo "No report generated"
            exit 1
          fi
          
      - name: Check Score Threshold
        run: |
          score=${{ steps.results.outputs.score }}
          threshold=80
          
          # Handle null/empty score
          if [ "$score" = "null" ] || [ -z "$score" ]; then
            echo "::error::No valid score generated"
            exit 1
          fi
          
          if (( $(echo "$score < $threshold" | bc -l) )); then
            echo "::error::Peer score below threshold: ${score}% (minimum: ${threshold}%)"
            exit 1
          else
            echo "::notice::Peer score: ${score}% (passed threshold: ${threshold}%)"
          fi
          
      - name: Generate HTML Report
        run: |
          if [ -f peer-score-report.json ]; then
            mkdir -p reports
            # Copy JSON report
            cp peer-score-report.json reports/
            # Copy HTML report (should be generated automatically by tool)
            if [ -f peer-score-report.html ]; then
              cp peer-score-report.html reports/index.html
            else
              echo "HTML report not found, tool may have failed to generate it"
              exit 1
            fi
          else
            echo "No JSON report found"
            exit 1
          fi
          
      - name: Upload Report Artifacts
        uses: actions/upload-artifact@v3
        with:
          name: peer-score-reports-${{ github.run_number }}
          path: reports/
          retention-days: 30
          
      - name: Setup Pages
        uses: actions/configure-pages@v3
        
      - name: Upload to Pages
        uses: actions/upload-pages-artifact@v2
        with:
          path: reports/
          
      - name: Generate Summary
        run: |
          connections=${{ steps.results.outputs.connections }}
          handshakes=${{ steps.results.outputs.handshakes }}
          
          # Calculate success rate safely
          if [ "$connections" -gt 0 ]; then
            success_rate=$(echo "scale=1; $handshakes * 100 / $connections" | bc)
          else
            success_rate="0"
          fi
          
          {
            echo "## ðŸ”— Peer Score Report"
            echo ""
            echo "**Overall Score:** ${{ steps.results.outputs.score }}%"
            echo ""
            echo "### Connection Statistics"
            echo "- **Total Connections:** $connections"
            echo "- **Successful Handshakes:** $handshakes"
            echo "- **Success Rate:** ${success_rate}%"
            echo "- **Goodbye Messages:** ${{ steps.results.outputs.goodbyes }}"
            echo ""
            echo "### Network Diversity" 
            echo "- **Unique Clients:** ${{ steps.results.outputs.clients }}"
            echo ""
            echo "### Summary"
            echo "${{ steps.results.outputs.summary }}"
            echo ""
            echo "_Report generated on $(date)_"
          } >> $GITHUB_STEP_SUMMARY
          
  deploy:
    needs: peer-score-test
    runs-on: ubuntu-latest
    
    permissions:
      pages: write
      id-token: write
      
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
      
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v2
