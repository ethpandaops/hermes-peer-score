name: Peer Score CI

on:
  schedule:
    # Run daily at 11 AM UTC
    - cron: '0 11 * * *'
  workflow_dispatch:
    inputs:
      duration:
        description: 'Test duration (e.g., 5m, 10m)'
        default: '5m'
        required: false
      chain:
        description: 'Chain'
        default: 'mainnet'
        required: false
      region:
        description: 'Prysm region'
        type: choice
        options:
          - SFO
          - SYD
        default: 'SFO'
        required: false

jobs:
  peer-score-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc

      - name: Build Latest Hermes
        run: |
          # Clone and build latest hermes from source
          git clone https://github.com/ethpandaops/hermes.git hermes-repo
          cd hermes-repo
          LATEST_COMMIT=$(git rev-parse --short HEAD)
          go build -o ../hermes ./cmd/hermes
          cd ..
          chmod +x ./hermes
          echo "Built Hermes from commit: $LATEST_COMMIT"

      - name: Build Peer Score Tool
        run: |
          go mod tidy
          go build -o peer-score-tool

      - name: Run Peer Score Test
        env:
          DURATION: ${{ github.event.inputs.duration || '5m' }}
          CHAIN: ${{ github.event.inputs.chain || 'mainnet' }}
          REGION: ${{ github.event.inputs.region || 'SFO' }}
        run: |
          # Select Prysm host based on region
          if [ "$REGION" = "SYD" ]; then
            PRYSM_HOST="${{ secrets.PRYSM_HOST_SYD }}"
          else
            PRYSM_HOST="${{ secrets.PRYSM_HOST_SFO }}"
          fi

          echo "Using Prysm host in $REGION region"

          ./peer-score-tool \
            --prysm-host="$PRYSM_HOST" \
            --prysm-http-port=443 \
            --prysm-grpc-port=443 \
            --duration="$DURATION" \
            --output=peer-score-report.json

      - name: Generate HTML Report
        run: |
          if [ -f peer-score-report.json ]; then
            mkdir -p reports
            # Copy JSON report
            cp peer-score-report.json reports/
            # Copy HTML report (should be generated automatically by tool)
            if [ -f peer-score-report.html ]; then
              cp peer-score-report.html reports/index.html
              # Copy the JavaScript data file that's generated with the HTML report
              if [ -f peer-score-report-data.js ]; then
                cp peer-score-report-data.js reports/
              else
                echo "Warning: JavaScript data file not found, HTML report may not function properly"
              fi
            else
              echo "HTML report not found, tool may have failed to generate it"
              exit 1
            fi
          else
            echo "No JSON report found"
            exit 1
          fi

      - name: Upload Report Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: peer-score-reports-${{ github.run_number }}
          path: reports/
          retention-days: 30

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: reports/

      - name: Parse Report Results
        id: results
        run: |
          if [ -f peer-score-report.json ]; then
            # Extract data from the new JSON format
            total_connections=$(jq -r '.total_connections // 0' peer-score-report.json)
            successful_handshakes=$(jq -r '.successful_handshakes // 0' peer-score-report.json)
            failed_handshakes=$(jq -r '.failed_handshakes // 0' peer-score-report.json)
            unique_peers=$(jq -r '.peers | length' peer-score-report.json)
            duration_seconds=$(jq -r '.duration / 1000000000' peer-score-report.json)
            test_duration=$(jq -r '.config.TestDuration / 1000000000' peer-score-report.json)

            # Count unique client types
            unique_clients=$(jq -r '[.peers[].client_type] | unique | length' peer-score-report.json)

            # Calculate success rate
            if [ "$total_connections" -gt 0 ]; then
              success_rate=$(echo "scale=1; $successful_handshakes * 100 / $total_connections" | bc)
            else
              success_rate="0"
            fi

            # Count total events
            total_events=$(jq -r '[.peer_event_counts[] | add] | add // 0' peer-score-report.json)

            # Set outputs
            echo "connections=$total_connections" >> $GITHUB_OUTPUT
            echo "successful_handshakes=$successful_handshakes" >> $GITHUB_OUTPUT
            echo "failed_handshakes=$failed_handshakes" >> $GITHUB_OUTPUT
            echo "success_rate=$success_rate" >> $GITHUB_OUTPUT
            echo "unique_peers=$unique_peers" >> $GITHUB_OUTPUT
            echo "unique_clients=$unique_clients" >> $GITHUB_OUTPUT
            echo "duration_seconds=$duration_seconds" >> $GITHUB_OUTPUT
            echo "test_duration=$test_duration" >> $GITHUB_OUTPUT
            echo "total_events=$total_events" >> $GITHUB_OUTPUT
          else
            echo "No JSON report found"
            exit 1
          fi

      - name: Generate Summary
        run: |
          # Use the parsed results
          connections=${{ steps.results.outputs.connections }}
          successful_handshakes=${{ steps.results.outputs.successful_handshakes }}
          failed_handshakes=${{ steps.results.outputs.failed_handshakes }}
          success_rate=${{ steps.results.outputs.success_rate }}
          unique_peers=${{ steps.results.outputs.unique_peers }}
          unique_clients=${{ steps.results.outputs.unique_clients }}
          duration_seconds=${{ steps.results.outputs.duration_seconds }}
          test_duration=${{ steps.results.outputs.test_duration }}
          total_events=${{ steps.results.outputs.total_events }}

          {
            echo "## ðŸ”— Peer Score Report"
            echo ""
            echo "### Test Configuration"
            echo "- **Test Duration:** ${test_duration}s"
            echo "- **Actual Duration:** ${duration_seconds}s"
            echo ""
            echo "### Connection Statistics"
            echo "- **Total Connections:** $connections"
            echo "- **Successful Handshakes:** $successful_handshakes"
            echo "- **Failed Handshakes:** $failed_handshakes"
            echo "- **Success Rate:** ${success_rate}%"
            echo ""
            echo "### Network Diversity"
            echo "- **Unique Peers Discovered:** $unique_peers"
            echo "- **Unique Client Types:** $unique_clients"
            echo "- **Total Events Captured:** $total_events"
            echo ""
            echo "### Report Files"
            echo "- ðŸ“Š [Interactive HTML Report](https://ethpandaops.github.io/hermes-peer-score/)"
            echo "- ðŸ“„ [Raw JSON Data](https://ethpandaops.github.io/hermes-peer-score/peer-score-report.json)"
            echo ""
            echo "_Report generated on $(date) using latest Hermes_"
          } >> $GITHUB_STEP_SUMMARY

  deploy:
    needs: peer-score-test
    runs-on: ubuntu-latest

    permissions:
      pages: write
      id-token: write

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
