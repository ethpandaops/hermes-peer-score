name: Independent Validation CI

on:
  schedule:
    # Run daily at 12 PM UTC - Independent validation without Prysm
    - cron: '0 12 * * *'
  workflow_dispatch:
    inputs:
      duration:
        description: 'Test duration (e.g., 5m, 10m, 30m)'
        default: '30m'
        required: false
      chain:
        description: 'Chain'
        default: 'mainnet'
        required: false
      region:
        description: 'Prysm region'
        type: choice
        options:
          - SFO
          - SYD
        default: 'SFO'
        required: false

jobs:
  independent-validation-test:
    runs-on: ubuntu-latest
    timeout-minutes: 300

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq bc

      - name: Configure Go Module for Independent Validation
        run: |
          echo "âš¡ Configuring Go module for independent validation mode"

          # Update go.mod for independent validation using the built-in function
          go run . --validation-mode=independent --update-go-mod

          # Ensure dependencies are properly resolved
          go mod tidy

          # Show the go.mod changes
          echo "Go module configuration:"
          cat go.mod | grep -A5 -B5 "hermes\|replace" || echo "No replace directives found"

      - name: Build Peer Score Tool
        run: |
          echo "ðŸ”§ Building peer score tool for independent validation"
          go build -o peer-score-tool

      - name: Validate Go Module Configuration
        run: |
          echo "âœ… Validating Go module configuration for independent validation"
          go run . --validation-mode=independent --validate-go-mod

      - name: Run Independent Validation Test
        env:
          DURATION: ${{ github.event.inputs.duration || '30m' }}
          CHAIN: ${{ github.event.inputs.chain || 'mainnet' }}
          REGION: ${{ github.event.inputs.region || 'SFO' }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_MODEL: ${{ vars.OPENROUTER_MODEL || 'deepseek/deepseek-r1' }}
        run: |
          # Select Prysm host based on region
          if [ "$REGION" = "SYD" ]; then
            PRYSM_HOST="${{ secrets.PRYSM_HOST_SYD }}"
          else
            PRYSM_HOST="${{ secrets.PRYSM_HOST_SFO }}"
          fi

          echo "âš¡ Running independent validation test using Prysm host in $REGION region (uses Prysm for beacon data, validates internally)"

          ./peer-score-tool \
            --validation-mode=independent \
            --prysm-host="$PRYSM_HOST" \
            --prysm-http-port=443 \
            --prysm-grpc-port=443 \
            --duration="$DURATION"

      - name: Generate HTML Report
        run: |
          # Find the timestamped independent JSON file
          INDEPENDENT_JSON=$(ls peer-score-report-independent-*.json 2>/dev/null | head -1)
          if [ -n "$INDEPENDENT_JSON" ] && [ -f "$INDEPENDENT_JSON" ]; then
            echo "ðŸ“Š Generating HTML report for independent validation"
            echo "Found JSON report: $INDEPENDENT_JSON"

            # Extract the generated timestamp from the filename
            GENERATED_TIMESTAMP=$(echo "$INDEPENDENT_JSON" | sed 's/peer-score-report-independent-\(.*\)\.json/\1/')
            echo "Extracted timestamp: $GENERATED_TIMESTAMP"

            # Create timestamp-based directory structure
            DATE_DIR=$(date -u +"%Y-%m-%d")

            # Ensure the reports directory exists
            mkdir -p "reports/$DATE_DIR"

            # Copy JSON report keeping the original filename format
            cp "$INDEPENDENT_JSON" "reports/$DATE_DIR/$INDEPENDENT_JSON"

            # Find and copy HTML report (should be generated automatically by tool)
            INDEPENDENT_HTML=$(ls peer-score-report-independent-*.html 2>/dev/null | head -1)
            if [ -n "$INDEPENDENT_HTML" ] && [ -f "$INDEPENDENT_HTML" ]; then
              echo "Found HTML report: $INDEPENDENT_HTML"
              cp "$INDEPENDENT_HTML" "reports/$DATE_DIR/$INDEPENDENT_HTML"

              # Copy the JavaScript data file that's generated with the HTML report
              INDEPENDENT_JS=$(ls peer-score-report-independent-*-data.js 2>/dev/null | head -1)
              if [ -n "$INDEPENDENT_JS" ] && [ -f "$INDEPENDENT_JS" ]; then
                echo "Found JS data file: $INDEPENDENT_JS"
                cp "$INDEPENDENT_JS" "reports/$DATE_DIR/$INDEPENDENT_JS"
              else
                echo "Warning: JavaScript data file not found, HTML report may not function properly"
              fi

            else
              echo "HTML report not found, tool may have failed to generate it"
              exit 1
            fi
          else
            echo "No JSON report found"
            exit 1
          fi

      - name: Generate Historical Index
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_MODEL: ${{ vars.OPENROUTER_MODEL || 'deepseek/deepseek-r1' }}
          VALIDATION_MODE: 'independent'
        run: |
          # Download existing reports manifest from GitHub Pages to preserve history
          echo "Attempting to preserve existing independent reports from GitHub Pages using manifest..."

          # Try to download the existing reports manifest
          MANIFEST_URL="https://${{ github.repository_owner }}.github.io/hermes-peer-score/reports-manifest.json"
          echo "Downloading reports manifest from: $MANIFEST_URL"

          if curl -f -s "$MANIFEST_URL" -o reports-manifest.json 2>/dev/null; then
            echo "Found existing reports manifest, downloading historical independent reports..."

            # Set cutoff date for 28-day retention
            CUTOFF_DATE=$(date -u -d "28 days ago" +"%Y-%m-%d")
            echo "Cutoff date for retention: $CUTOFF_DATE"

            # Download historical reports using the manifest
            CUTOFF_DATE="$CUTOFF_DATE" VALIDATION_MODE="independent" python3 scripts/download_reports.py
          else
            echo "No existing reports manifest found - this might be the first independent run"
          fi

          # Clean up any independent directories older than 28 days
          echo "Cleaning up independent reports older than 28 days..."
          find reports -maxdepth 2 -type d -path "*/independent" | while read dir; do
            DIR_DATE=$(basename $(dirname "$dir"))
            if [ "$DIR_DATE" != "reports" ]; then
              # Calculate if this directory is older than 28 days
              DIR_EPOCH=$(date -d "$DIR_DATE" +%s 2>/dev/null || echo "0")
              CUTOFF_EPOCH=$(date -d "28 days ago" +%s)

              if [ "$DIR_EPOCH" -lt "$CUTOFF_EPOCH" ] && [ "$DIR_EPOCH" -gt "0" ]; then
                echo "Removing old independent reports from $DIR_DATE"
                rm -rf "$dir"
              fi
            fi
          done

          echo "Independent cleanup complete, generating new index..."

          # Generate the historical index page and manifest
          VALIDATION_MODE="independent" python3 scripts/generate_index.py

      - name: Upload Report Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: independent-validation-reports-${{ github.run_number }}
          path: reports/
          retention-days: 30

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: reports/

      - name: Parse Report Results
        id: results
        run: |
          # Find the timestamped independent JSON file
          INDEPENDENT_JSON=$(ls peer-score-report-independent-*.json 2>/dev/null | head -1)
          if [ -n "$INDEPENDENT_JSON" ] && [ -f "$INDEPENDENT_JSON" ]; then
            echo "Parsing results from: $INDEPENDENT_JSON"
            # Extract data from the new JSON format
            validation_mode=$(jq -r '.validation_mode // "independent"' "$INDEPENDENT_JSON")
            hermes_version=$(jq -r '.validation_config.hermes_version // "unknown"' "$INDEPENDENT_JSON")
            total_connections=$(jq -r '.total_connections // 0' "$INDEPENDENT_JSON")
            successful_handshakes=$(jq -r '.successful_handshakes // 0' "$INDEPENDENT_JSON")
            failed_handshakes=$(jq -r '.failed_handshakes // 0' "$INDEPENDENT_JSON")
            unique_peers=$(jq -r '.peers | length' "$INDEPENDENT_JSON")
            duration_seconds=$(jq -r '.duration / 1000000000' "$INDEPENDENT_JSON")
            test_duration=$(jq -r '.config.TestDuration / 1000000000' "$INDEPENDENT_JSON")

            # Extract validation metrics (these fields were removed, so default to 0)
            validation_success_rate=0
            avg_latency_ms=0
            messages_per_sec=0
            error_rate=0
            cpu_usage=0
            memory_usage=0
            cache_hit_rate=0

            # Count unique client types
            unique_clients=$(jq -r '[.peers[].client_type] | unique | length' "$INDEPENDENT_JSON")

            # Calculate success rate
            if [ "$total_connections" -gt 0 ]; then
              success_rate=$(echo "scale=1; $successful_handshakes * 100 / $total_connections" | bc)
            else
              success_rate="0"
            fi

            # Count total events
            total_events=$(jq -r '[.peer_event_counts[] | add] | add // 0' "$INDEPENDENT_JSON")

            # Set outputs
            echo "validation_mode=$validation_mode" >> $GITHUB_OUTPUT
            echo "hermes_version=$hermes_version" >> $GITHUB_OUTPUT
            echo "connections=$total_connections" >> $GITHUB_OUTPUT
            echo "successful_handshakes=$successful_handshakes" >> $GITHUB_OUTPUT
            echo "failed_handshakes=$failed_handshakes" >> $GITHUB_OUTPUT
            echo "success_rate=$success_rate" >> $GITHUB_OUTPUT
            echo "unique_peers=$unique_peers" >> $GITHUB_OUTPUT
            echo "unique_clients=$unique_clients" >> $GITHUB_OUTPUT
            echo "duration_seconds=$duration_seconds" >> $GITHUB_OUTPUT
            echo "test_duration=$test_duration" >> $GITHUB_OUTPUT
            echo "total_events=$total_events" >> $GITHUB_OUTPUT
            echo "validation_success_rate=$validation_success_rate" >> $GITHUB_OUTPUT
            echo "avg_latency_ms=$avg_latency_ms" >> $GITHUB_OUTPUT
            echo "messages_per_sec=$messages_per_sec" >> $GITHUB_OUTPUT
            echo "error_rate=$error_rate" >> $GITHUB_OUTPUT
            echo "cpu_usage=$cpu_usage" >> $GITHUB_OUTPUT
            echo "memory_usage=$memory_usage" >> $GITHUB_OUTPUT
            echo "cache_hit_rate=$cache_hit_rate" >> $GITHUB_OUTPUT
          else
            echo "No JSON report found"
            exit 1
          fi

      - name: Generate Summary
        run: |
          # Use the parsed results
          validation_mode=${{ steps.results.outputs.validation_mode }}
          hermes_version=${{ steps.results.outputs.hermes_version }}
          connections=${{ steps.results.outputs.connections }}
          successful_handshakes=${{ steps.results.outputs.successful_handshakes }}
          failed_handshakes=${{ steps.results.outputs.failed_handshakes }}
          success_rate=${{ steps.results.outputs.success_rate }}
          unique_peers=${{ steps.results.outputs.unique_peers }}
          unique_clients=${{ steps.results.outputs.unique_clients }}
          duration_seconds=${{ steps.results.outputs.duration_seconds }}
          test_duration=${{ steps.results.outputs.test_duration }}
          total_events=${{ steps.results.outputs.total_events }}
          validation_success_rate=${{ steps.results.outputs.validation_success_rate }}
          avg_latency_ms=${{ steps.results.outputs.avg_latency_ms }}
          messages_per_sec=${{ steps.results.outputs.messages_per_sec }}
          error_rate=${{ steps.results.outputs.error_rate }}
          cpu_usage=${{ steps.results.outputs.cpu_usage }}
          memory_usage=${{ steps.results.outputs.memory_usage }}
          cache_hit_rate=${{ steps.results.outputs.cache_hit_rate }}

          {
            echo "## âš¡ Independent Validation Report"
            echo ""
            echo "### Validation Configuration"
            echo "- **Mode:** Independent Validation (in-process)"
            echo "- **Hermes Version:** $hermes_version"
            echo "- **Test Duration:** ${test_duration}s"
            echo "- **Actual Duration:** ${duration_seconds}s"
            echo ""
            echo "### Connection Statistics"
            echo "- **Total Connections:** $connections"
            echo "- **Successful Handshakes:** $successful_handshakes"
            echo "- **Failed Handshakes:** $failed_handshakes"
            echo "- **Success Rate:** ${success_rate}%"
            echo ""
            echo "### Validation Performance"
            echo "- **Validation Success Rate:** $(echo "scale=1; $validation_success_rate * 100" | bc)%"
            echo "- **Average Latency:** ${avg_latency_ms}ms"
            echo "- **Message Processing Rate:** ${messages_per_sec} msg/sec"
            echo "- **Error Rate:** $(echo "scale=2; $error_rate * 100" | bc)%"
            echo ""
            echo "### Resource Utilization"
            echo "- **CPU Usage:** ${cpu_usage}%"
            echo "- **Memory Usage:** ${memory_usage}MB"
            echo "- **Cache Hit Rate:** $(echo "scale=1; $cache_hit_rate * 100" | bc)%"
            echo ""
            echo "### Network Diversity"
            echo "- **Unique Peers Discovered:** $unique_peers"
            echo "- **Unique Client Types:** $unique_clients"
            echo "- **Total Events Captured:** $total_events"
            echo ""
            echo "### Report Files"
            echo "- ðŸ“Š [Interactive HTML Report](https://ethpandaops.github.io/hermes-peer-score/)"
            echo "- ðŸ“„ [Raw JSON Data](https://ethpandaops.github.io/hermes-peer-score/)"
            echo ""
            echo "_Independent validation report generated on $(date) using Hermes $hermes_version_"
          } >> $GITHUB_STEP_SUMMARY

  deploy:
    needs: independent-validation-test
    runs-on: ubuntu-latest

    permissions:
      pages: write
      id-token: write

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
